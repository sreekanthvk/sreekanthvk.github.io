<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Career Page">
    <meta name="author" content="Anjith George">

    <title>Anjith George - Homepage</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.css" rel="stylesheet">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">

    <!-- Custom CSS -->
    <link href="css/1-col-portfolio.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-69511238-1', 'auto');
      ga('send', 'pageview');

    </script>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>
<body data-gr-c-s-loaded="true" data-feedly-mini="yes">

  <div class="wrapper">
    <aside class="sidebar">
  <header>
    <div class="about">
      <div class="cover-author-image">
        <a href=""><img src="Figures/anjith.png" alt="Anjith George"></a>
      </div>
      <div class="author-name">Anjith George</div>
      <p>Computer Vision &amp; Machine Learning Researcher</p>
      <article class="article-page"><div class="page-content"><div class="wrap-content"><header class="header-page">
      <h3 class="page-sidebarmenu"><a href="index.html">About</a></h3>
      &nbsp; &nbsp; <h3 class="page-sidebarmenu"><a href="research.html">Research</a></h3>
      &nbsp; &nbsp; <h3 class="page-sidebarmenu"><a href="publications.html">Publications</a></h3>
      &nbsp; &nbsp; <h3 class="page-sidebarmenu"><a href="resume.html">CV</a></h3>
      &nbsp; &nbsp; <h3 class="page-sidebarmenu"><a href="resources.html">Resources</a></h3>
      &nbsp; &nbsp; <h3 class="page-sidebarmenu"><a href="demos.html">Demos</a></h3>
      </header></div></div></article>
    </div>
  </header> <!-- End Header -->  
  




    <section class="contact">
      <h3 class="contact-title">Contact me</h3>
      <ul>
        
        
          <li class="github"><a href="http://github.com/anjith2006" target="_blank"><i class="fa fa-github"></i></a></li>
        
        
          <li class="linkedin"><a href="https://ch.linkedin.com/in/anjith-george-ph-d-87402529" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        
        
          <li><a href="https://www.youtube.com/channel/UCF-4bAPWrVmkLxQRTjDz0yQ" target="_blank"><i class="fa fa-youtube" aria-hidden="true"></i></a></li>
        
        
          <li class="email"><a href="mailto:anjith2006@gmail.com"><i class="fa fa-envelope-o"></i></a></li>
        
      </ul>
    </section> <!-- End Section Contact -->
    <div class="copyright">
      <p>  2024 Â© Anjith George  </p>
    </div>
  </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->
<div class="content-box clearfix">



    <br><br>
    <!-- Project One -->
     <div class="pubwrap">
  <div class="row">
    <div class="col-md-6">
      <div class="pubimg">
        <br><br><br>
        <img src="Figures/MCCNN.jpg">
      </div>
    </div>
   <div class="col-md-6">
    <div class="pub">
    <div class="pubt"> Biometric Face Presentation Attack Detection with Multi-Channel Convolutional Neural Network</div>
    <hr><br>
    <div class="pubd">
      <p align = "justify"> Face recognition is a mainstream biometric authentication method. However, vulnerability to presentation attacks (a.k.a spoofing) limits its usability in unsupervised applications. Even though there are many methods available for tackling presentation attacks (PA), most of them fail to detect sophisticated attacks such as silicone masks.
As the quality of presentation attack instruments improves over time, achieving reliable PA detection with visual spectra alone remains very challenging. We argue that analysis in multiple channels might help to address this issue.  In this context, we propose a multi-channel Convolutional Neural Network based approach for presentation attack detection (PAD).
We also introduce the new Wide Multi-Channel presentation Attack (WMCA) database for face PAD which contains a wide variety of 2D and 3D presentation attacks for both impersonation and obfuscation attacks. Data from different channels such as color, depth, near-infrared and thermal are available to advance the research in face PAD. The proposed method was compared with feature-based approaches and found to outperform the baselines achieving an ACER of 0.3% on the introduced dataset. The database and the software to reproduce the results are made available publicly.</p> </div>
    <div class="puba"> IEEE TIFS 2019</div>
    <div class="pubv">Accepted</div>
    <div class="publ">
    <ul>
    <li><a href = "http://publications.idiap.ch/downloads/papers/2019/George_TIFS_2019.pdf">Link</a></li>
    </ul>
    </div>
      </div>
    </div>
  </div>
</div>
<br><br>



    <br><br>
    <!-- Project One -->
     <div class="pubwrap">
  <div class="row">
    <div class="col-md-6">
      <div class="pubimg">
        <br><br><br>
        <img src="Figures/PixBis.png">
      </div>
    </div>
   <div class="col-md-6">
    <div class="pub">
    <div class="pubt"> Deep Pixel-wise Binary Supervision for Face Presentation Attack Detection</div>
    <hr><br>
    <div class="pubd">
      <p align = "justify"> Face recognition has evolved as a prominent biometric authentication modality. However, vulnerability to presentation attacks curtails its reliable deployment. Automatic detection of presentation attacks is essential for secure use of face recognition technology in unattended scenarios. In this work, we introduce a Convolutional Neural Network (CNN) based framework for presentation attack detection, with deep pixel-wise supervision. The framework uses only frame level information making it suitable for deployment in smart devices with minimal computational and time overhead. We demonstrate the effectiveness of the proposed approach in public datasets for both intra as well as cross-dataset experiments. The proposed approach achieves an HTER of 0% in Replay Mobile dataset and an ACER of 0.42% in Protocol-1 of OULU dataset outperforming state of the art methods.</p> </div>
    <div class="puba"> ICB 2019</div>
    <div class="pubv">Accepted</div>
    <div class="publ">
    <ul>
    <li><a href = "http://publications.idiap.ch/downloads/papers/2019/George_ICB2019.pdf">Link</a></li>
    </ul>
    </div>
      </div>
    </div>
  </div>
</div>
<br><br>




    <br><br>
    <!-- Project One -->
     <div class="pubwrap">
  <div class="row">
    <div class="col-md-6">
      <div class="pubimg">
        <br><br><br>
        <img src="Figures/AE_PAD.png">
      </div>
    </div>
   <div class="col-md-6">
    <div class="pub">
    <div class="pubt"> Domain Adaptation in Multi-Channel Autoencoder based Features for Robust Face Anti-Spoofing</div>
    <hr><br>
    <div class="pubd">
      <p align = "justify"> While the performance of face recognition systems has improved significantly in the last decade, they are proved to be highly vulnerable to presentation attacks (spoofing). Most of the research in the field of face presentation attack detection (PAD), was focused on boosting the performance of the systems within a single database. Face PAD datasets are usually captured with RGB cameras, and have very limited number of both bona-fide samples and presentation attack instruments. Training face PAD systems on such data leads to poor performance, even in the closed-set scenario, especially when sophisticated attacks are involved.
   We explore two paths to boost the performance of the face PAD system against challenging attacks. First, by using multi-channel (RGB, Depth and NIR) data, which is still easily accessible in a number of mass production devices. Second, we develop a novel Autoencoders + MLP based face PAD algorithm. Moreover, instead of collecting more data for training of the proposed deep architecture, the domain adaptation technique is proposed, transferring the knowledge of facial appearance from RGB to multi-channel domain. We also demonstrate, that learning the features of individual facial regions, is more discriminative than the features learned from an entire face. The proposed system is tested on a very recent publicly available multi-channel PAD database with a wide variety of presentation attacks.</p> </div>
    <div class="puba"> ICB 2019</div>
    <div class="pubv">Accepted</div>
    <div class="publ">
    <ul>
    <li><a href = "http://publications.idiap.ch/downloads/papers/2019/Nikisins_ICB_2019.pdf">Link</a></li>
    </ul>
    </div>
      </div>
    </div>
  </div>
</div>
<br><br>



    <br><br>
    <!-- Project One -->
     <div class="pubwrap">
  <div class="row">
    <div class="col-md-6">
      <div class="pubimg">
        <br><br><br>
        <img src="Figures/dataseteyes.jpg">
      </div>
    </div>
   <div class="col-md-6">
    <div class="pub">
    <div class="pubt"> Fast and Accurate Eye Localization Algorithm for Gaze Tracking in Low Resolution Images</div>
    <hr><br>
    <div class="pubd">
      <p align = "justify"> Iris centre localization in low-resolution visible images is a challenging problem in
computer vision community due to noise, shadows, occlusions, pose variations, eye blinks, etc. This
paper proposes an efficient method for determining iris centre in low-resolution images in the visible
spectrum. Even low-cost consumer-grade webcams can be used for gaze tracking without any
additional hardware. A two-stage algorithm is proposed for iris centre localization. The proposed
method uses geometrical characteristics of the eye. In the first stage, a fast convolution based
approach is used for obtaining the coarse location of iris centre (IC). The IC location is further
refined in the second stage using boundary tracing and ellipse fitting. The algorithm has been
evaluated in public databases like BioID, Gi4E and is found to outperform the state of the art
methods. </p> </div>
    <div class="puba"> IET Computer Vision</div>
    <div class="pubv">DOI: 10.1049/iet-cvi.2015.0316 0</div>
    <div class="publ">
    <ul>
    <li><a href = "http://dx.doi.org/10.1049/iet-cvi.2015.0316">Link</a></li>
    </ul>
    </div>
      </div>
    </div>
  </div>
</div>
<br><br>




        <!-- Project One -->

        <!-- Project One -->
         <div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <br><br><br>
            <img src="Figures/cnn3.jpg">
          </div>
        </div>
        <div class="col-md-6">
        <div class="pub">
        <div class="pubt"> Real-time Eye Gaze Direction Classification Using Convolutional Neural Network</div>
        <hr><br>
        <div class="pubd">
          <p align = "justify"> Estimation eye gaze direction is useful in various
human-computer interaction tasks. Knowledge of gaze direction
can give valuable information regarding users point of attention.
Certain patterns of eye movements known as eye accessing cues
are reported to be related to the cognitive processes in the human
brain. We propose a real-time framework for the classification
of eye gaze direction and estimation of eye accessing cues. In
the first stage, the algorithm detects faces using a modified
version of the Viola-Jones algorithm. A rough eye region is
obtained using geometric relations and facial landmarks. The eye
region obtained is used in the subsequent stage to classify the
eye gaze direction. A convolutional neural network is employed
in this work for the classification of eye gaze direction. The
proposed algorithm was tested on Eye Chimera database and
found to outperform state of the art methods. The computational
complexity of the algorithm is very less in the testing phase. The
algorithm achieved an average frame rate of 24 fps in the desktop
environment. </p> </div>
        <div class="puba"> SPCOM, 2016</div>
        <div class="pubv">SPCOM, IEEE</div>
        <div class="publ">
        <ul>
        <li><a href = "http://arxiv.org/find/all/1/all:+AND+anjith+george/0/1/0/all/0/1"> arXiv Link</a></li>
        </ul>
        </div>
          </div>
        </div>
      </div>
      </div>
      <br><br>

            <!-- Project One -->


        <!------>
         <div class="pubwrap">
			<div class="row">
				<div class="col-md-6">
					<div class="pubimg">
						<br><br><br>
						<img src="Figures/eyemovement.jpg">
					</div>
				</div>
				<div class="col-md-6">
				<div class="pub">
				<div class="pubt"> A Score-level Fusion Method for Eye Movement Biometrics</div>
        <hr><br>
				<div class="pubd">
          <p align = "justify"> Eye movements contain abundant information about cognitive brain functions, neural pathways,
etc. In our approach, eye movement data is classified into fixations and saccades. Features extracted from fixations and saccades are used in a machine learning
framework for biometric authentication. A score fusion approach is adopted to classify the data
in the output layer. In the evaluation stage, the algorithm has been tested using two types of stimuli:
random dot following on a screen and text reading. The results indicate the strength of eye movement
pattern as a biometric modality. The algorithm has been evaluated on BioEye 2015 database and found
to outperform all the other methods. Eye movements are generated by a complex oculomotor plant
which is very hard to spoof by mechanical replicas. Use of eye movement dynamics along with iris
recognition technology may lead to a robust counterfeit-resistant person identification system. </p> </div>
				<div class="puba"> Pattern Recognition Letters</div>
				<div class="pubv">DOI:10.1016/j.patrec.2015.11.020</div>
				<div class="publ">
				<ul>
				<li><a href = "http://www.sciencedirect.com/science/article/pii/S0167865515004067">Link</a></li>
				</ul>
				</div>
					</div>
				</div>
			</div>
		</div>
		<br><br>
        <!-- Project One -->
         <div class="pubwrap">
			<div class="row">
				<div class="col-md-6">
					<div class="pubimg">
						<br><br><br>
						<img src="Figures/driver.png">
					</div>
				</div>
				<div class="col-md-6">
				<div class="pub">
				<div class="pubt"> A Vision Based System for Monitoring the Loss of Attention in Automotive Drivers</div>
        <hr><br>
				<div class="pubd"> <p align = "justify">On board monitoring of the alertness level of an automotive driver has been a challenging research in transportation safety and management. In this paper, we propose a robust real time embedded platform to monitor the loss of attention of the driver during day as well as night driving conditions. The PERcentage of eye CLOSure (PERCLOS) has been used as the indicator of the alertness level.  The algorithm has been cross validated using brain signals and finally been implemented on a Single Board Computer (SBC). The system is found to be robust under actual driving conditions.  </div>
			</p>	<div class="puba"> 	Intelligent Transportation Systems, IEEE Transactions on 14, no. 4 (2013): 1825-1838</div>
				<div class="pubv">DOI: 10.1109/TITS.2013.2271052</div>
				<div class="publ">
				<ul>
				<li><a href = "http://arxiv.org/find/all/1/all:+AND+anjith+george/0/1/0/all/0/1">arXiv Link</a></li>
				</ul>
				</div>
					</div>
				</div>
			</div>
		</div>


    <br><br>
        <!-- Project One -->
         <div class="pubwrap">
			<div class="row">
				<div class="col-md-6">
					<div class="pubimg">
						<br><br><br>
						<img src="Figures/expressions.png">
					</div>
				</div>
				<div class="col-md-6">
				<div class="pub">
				<div class="pubt"> A Real Time Facial Expression Classification System Using Local Binary Patterns</div>
        <hr><br>
				<div class="pubd"> <p align = "justify">Facial expression analysis is one of the popular fields
of research in human computer interaction (HCI). It has several
applications in next generation user interfaces, human emotion
analysis, behavior and cognitive modeling. In this paper, a facial
expression classification algorithm is proposed which uses Haar
classifier for face detection purpose, Local Binary Patterns(LBP)
histogram of different block sizes of a face image as feature
vectors and classifies various facial expressions using Principal
Component Analysis (PCA). The algorithm is implemented in
real time for expression classification since the computational
complexity of the algorithm is small. A customizable approach is
proposed for facial expression analysis, since the various
expressions and intensity of expressions vary from person to
person. The system uses grayscale frontal face images of a person
to classify six basic emotions namely happiness, sadness, disgust,
fear, surprise and anger. </p> </div>
				<div class="puba">IEEE Proceedings of 4 th International Conference on Intelligent Human Computer Interaction</div>
				<div class="publ">
				<ul>
				<li><a href = "http://arxiv.org/find/all/1/all:+AND+anjith+george/0/1/0/all/0/1">arXiv Link</a></li>
				</ul>
				</div>
					</div>
				</div>
			</div>
		</div>




        <br><br>
            <!-- Project One -->
             <div class="pubwrap">
    			<div class="row">
    				<div class="col-md-6">
    					<div class="pubimg">
    						<br><br><br>
    						<img src="Figures/nir.png">
    					</div>
    				</div>
    				<div class="col-md-6">
    				<div class="pub">
    				<div class="pubt"> A Video Database of Human Faces under Near Infra-Red
Illumination for Human Computer Interaction Aplications</div>
            <hr><br>
    				<div class="pubd"> <p align = "justify">Human Computer Interaction (HCI) is an evolving area
of research for coherent communication between computers and
human beings. Some of the important applications of HCI as
reported in literature are face detection, face pose estimation, face
tracking and eye gaze estimation. Development of algorithms for
these applications is an active field of research. However,
availability of standard database to validate such algorithms is
insufficient. This paper discusses the creation of such a database
created under Near Infra-Red (NIR) illumination. NIR
illumination has gained its popularity for night mode applications
since prolonged exposure to Infra-Red (IR) lighting may lead to
many health issues. The database contains NIR videos of 60
subjects in different head orientations and with different facial
expressions, facial occlusions and illumination variation. This new
database can be a very valuable resource for development and
evaluation of algorithms on face detection, eye detection, head
tracking, eye gaze tracking etc. in NIR lighting. </p> </div>
    				<div class="puba">IEEE Proceedings of 4 th International Conference on Intelligent Human Computer Interaction</div>
    				<div class="publ">
    				<ul>
    				<li><a href = "https://sites.google.com/site/nirdatabase/download">Database Download Link</a></li>
    				</ul>
    				</div>
    					</div>
    				</div>
    			</div>
    		</div>



                <br><br>
                    <!-- Project One -->
                     <div class="pubwrap">
            			<div class="row">
            				<div class="col-md-6">
            					<div class="pubimg">
            						<br><br><br>
            						<img src="Figures/fast.png">
            					</div>
            				</div>
            				<div class="col-md-6">
            				<div class="pub">
            				<div class="pubt"> A Framework for Fast Face and Eye Detection</div>
                    <hr><br>
            				<div class="pubd"> <p align = "justify">Face detection is an essential step in many computer
vision applications like surveillance, tracking, medical analysis,
facial expression analysis etc. Several approaches have been made
in the direction of face detection. Among them, Haar-like features
based method is a robust method. In spite of the robustness,
Haar - like features work with some limitations. However, with
some simple modifications in the algorithm, its performance can
be made faster and more robust. The present work refers to
the increase in speed of operation of the original algorithm by
down sampling the frames and its analysis with different scale
factors. It also discusses the detection of tilted faces using an
affine transformation of the input image. </p> </div>
            				<div class="puba">arXiv</div>
            				<div class="publ">
            				<ul>
            					<li><a href = "http://arxiv.org/find/all/1/all:+AND+anjith+george/0/1/0/all/0/1">arXiv Link</a></li>
            				</ul>
            				</div>
            					</div>
            				</div>
            			</div>
            		</div>




    <!-- /.container -->

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

</body>

</html>
